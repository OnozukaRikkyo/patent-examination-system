"""
ç‰¹è¨±å¯©æŸ»ã®æ®µéšçš„é€²æ­©æ€§åˆ¤æ–­ã‚·ã‚¹ãƒ†ãƒ  (çµ±åˆç‰ˆ)
å¹¹ï¼ˆClaim 1ï¼‰ã¨æè‘‰ï¼ˆClaim 2ä»¥é™ï¼‰ã‚’æ®µéšçš„ã«æ¤œè¨¼

ã€çµ±åˆã•ã‚ŒãŸç‰¹å¾´ã€‘
- ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã«ã‚ˆã‚‹å‹å®‰å…¨æ€§ (llm_pipeline.py)
- ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³æ–¹å¼ã«ã‚ˆã‚‹æ–‡è„ˆä¿æŒ (llm_pipline_gemini.py)
- å …ç‰¢ãªJSONãƒ‘ãƒ¼ã‚¹å‡¦ç† (llm_pipeline_chatgpt.py)
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å¤–éƒ¨åŒ– (llm_pipline_gemini.py)
- è©³ç´°ãªé€²æ—è¡¨ç¤ºã¨çµæœä¿å­˜ (llm_pipeline.py)

ã€è¿½åŠ ã•ã‚ŒãŸç‰¹å¾´ (2025/11/08)ã€‘
- AIãƒ¢ãƒ‡ãƒ«2, 3, 4ã«ã‚ˆã‚‹å…ˆè¡ŒæŠ€è¡“èª¿æŸ»ã®ãŸã‚ã®æ¤œç´¢ã‚¯ã‚¨ãƒªæ‹¡å¼µæ©Ÿèƒ½
- PatentSearchExpander ã‚¯ãƒ©ã‚¹ã®è¿½åŠ 
"""

import google.generativeai as genai
import os
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
import json
from dotenv import load_dotenv
import time
from google.api_core import exceptions as google_exceptions
import re


# ==================== ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹å®šç¾© ====================

@dataclass
class ClaimStructure:
    """ã‚¯ãƒ¬ãƒ¼ãƒ æ§‹é€ ã‚’ä¿æŒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    claim_number: int
    requirements: List[str]
    additional_limitations: Optional[List[str]] = None


@dataclass
class PatentDocument:
    """ç‰¹è¨±æ–‡çŒ®ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿"""
    problem: str
    solution_principle: str
    claim1_requirements: List[str]
    claim2_limitations: Optional[List[str]] = None
    claim3_limitations: Optional[List[str]] = None
    abstract_hints: Optional[Dict[str, str]] = None


# ==================== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ ====================

class PromptTemplates:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    # --- å…ƒã®é€²æ­©æ€§åˆ¤æ–­ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (ãã®ã¾ã¾) ---
    STEP_0_1_STRUCTURE_APPLICATION = """ï¼ˆ...çœç•¥: å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ...ï¼‰"""
    STEP_0_2_STRUCTURE_PRIOR_ART = """ï¼ˆ...çœç•¥: å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ...ï¼‰"""
    STEP_1_APPLICANT_ARGUMENTS = """ï¼ˆ...çœç•¥: å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ...ï¼‰"""
    STEP_2_EXAMINER_REVIEW = """ï¼ˆ...çœç•¥: å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ...ï¼‰"""
    STEP_3_FINAL_DECISION = """ï¼ˆ...çœç•¥: å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ...ï¼‰"""

    # --- ã“ã“ã‹ã‚‰AIãƒ¢ãƒ‡ãƒ«2, 3, 4ç”¨ã®æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ---

    MODEL_2_DECOMPOSE = """ã‚ãªãŸã¯ç‰¹è¨±åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®ã€Œæœ¬é¡˜ç™ºæ˜ã®è«‹æ±‚é …ã€ã‚’èª­ã¿ã€ãã®ç™ºæ˜ã‚’æ§‹æˆã™ã‚‹**ç‹¬ç«‹ã—ãŸæŠ€è¡“çš„æ§‹æˆè¦ç´ ï¼ˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼‰**ã«åˆ†è§£ã—ã¦ãã ã•ã„ã€‚

ã€æœ¬é¡˜ç™ºæ˜ã®è«‹æ±‚é …ã€‘
{claims_text}

---
ã€åˆ¶ç´„äº‹é …ã€‘
- å„æ§‹æˆè¦ç´ ã¯ã€ç™ºæ˜ã®å¿…é ˆã®æ§‹æˆãŒåˆ†ã‹ã‚‹ã‚ˆã†ã«ç°¡æ½”ã«è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚
- å‡ºåŠ›ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã¨ã—ã¦ãã ã•ã„ã€‚

ã€æ§‹é€ åŒ–å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
{{
  "components": [
    "æ§‹æˆè¦ç´ Aï¼ˆä¾‹ï¼šã‚¤ãƒ³ã‚¯æ»´ã‚’åå‡ºã™ã‚‹ãƒ—ãƒªãƒ³ãƒˆãƒ˜ãƒƒãƒ‰ï¼‰",
    "æ§‹æˆè¦ç´ Bï¼ˆä¾‹ï¼šãƒ—ãƒªãƒ³ãƒˆãƒ˜ãƒƒãƒ‰ã‚’è¦†ã†ç–æ²¹æ€§è¢«è†œï¼‰",
    "æ§‹æˆè¦ç´ Cï¼ˆä¾‹ï¼šè¢«è†œã®ç‰¹å®šã®ç†±å®‰å®šæ€§ï¼ˆ300â„ƒã§15%æœªæº€ã®é‡é‡æå¤±ï¼‰ï¼‰",
    "æ§‹æˆè¦ç´ Dï¼ˆä¾‹ï¼šè¢«è†œã®ç‰¹å®šã®ç‰©æ€§ï¼ˆæ¥è§¦è§’åº¦50Â°è¶…ã€æ»‘èµ°è§’åº¦30Â°æœªæº€ï¼‰ï¼‰"
  ]
}}
"""

    MODEL_3_CLASSIFY_ELEMENTS = """ã‚ãªãŸã¯ç‰¹è¨±åˆ†é¡ï¼ˆIPC/CPCï¼‰ã®å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®ã€ŒæŠ€è¡“çš„æ§‹æˆè¦ç´ ã€ã®ãƒªã‚¹ãƒˆã«ã¤ã„ã¦ã€**ãã‚Œãã‚Œã«**é–¢é€£ã™ã‚‹ç‰¹è¨±åˆ†é¡ã‚³ãƒ¼ãƒ‰ï¼ˆIPCã¾ãŸã¯CPCï¼‰ã‚’äºˆæ¸¬ã—ã¦ãã ã•ã„ã€‚

ã€æŠ€è¡“çš„æ§‹æˆè¦ç´ ãƒªã‚¹ãƒˆã€‘
{components_list}

---
ã€åˆ¶ç´„äº‹é …ã€‘
- å„æ§‹æˆè¦ç´ ã«å¯¾ã—ã¦ã€æœ€ã‚‚é–¢é€£æ€§ãŒé«˜ã„ã¨äºˆæ¸¬ã•ã‚Œã‚‹åˆ†é¡ã‚³ãƒ¼ãƒ‰ã‚’3ã¤æŒ™ã’ã¦ãã ã•ã„ã€‚
- å‡ºåŠ›ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã¨ã—ã¦ãã ã•ã„ã€‚

ã€æ§‹é€ åŒ–å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
{{
  "component_classifications": [
    {{
      "component": "æ§‹æˆè¦ç´ Aï¼ˆä¾‹ï¼šã‚¤ãƒ³ã‚¯æ»´ã‚’åå‡ºã™ã‚‹ãƒ—ãƒªãƒ³ãƒˆãƒ˜ãƒƒãƒ‰ï¼‰",
      "predicted_codes": ["B41J 2/14", "B41J 2/16", "B41J 2/045"]
    }},
    {{
      "component": "æ§‹æˆè¦ç´ Bï¼ˆä¾‹ï¼šãƒ—ãƒªãƒ³ãƒˆãƒ˜ãƒƒãƒ‰ã‚’è¦†ã†ç–æ²¹æ€§è¢«è†œï¼‰",
      "predicted_codes": ["B41J 2/16", "C09D 127/12", "C23C 14/06"]
    }}
  ]
}}
"""

    MODEL_4_EXPAND_SEARCH = """ã‚ãªãŸã¯ãƒ™ãƒ†ãƒ©ãƒ³ã®ç‰¹è¨±èª¿æŸ»å“¡ï¼ˆã‚µãƒ¼ãƒãƒ£ãƒ¼ï¼‰ã§ã™ã€‚
å…ˆè¡ŒæŠ€è¡“èª¿æŸ»ã®ç¶²ç¾…æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã€ä»¥ä¸‹ã®ã€Œæ—¢çŸ¥ã®åˆ†é¡ã‚³ãƒ¼ãƒ‰ã€ã®ãƒªã‚¹ãƒˆã«åŸºã¥ãã€**çµ±è¨ˆçš„ã¾ãŸã¯æ„å‘³çš„ã«é–¢é€£ãŒæ·±ãã€å…ˆè¡Œæ–‡çŒ®ãŒå­˜åœ¨ã—ã†ã‚‹**ä»–ã®åˆ†é¡ã‚³ãƒ¼ãƒ‰ã‚’æ¨è–¦ã—ã¦ãã ã•ã„ã€‚

ã€æ—¢çŸ¥ã®åˆ†é¡ã‚³ãƒ¼ãƒ‰ã€‘
{class_codes_list}

---
ã€åˆ¶ç´„äº‹é …ã€‘
- ãªãœãã®ã‚³ãƒ¼ãƒ‰ã‚’æ¨è–¦ã™ã‚‹ã®ã‹ã€ç°¡æ½”ãªç†ç”±ï¼ˆä¾‹ï¼šã€ŒB41J 2/14ã€ã®é–¢é€£æŠ€è¡“ã€ã€ŒC09Dã€ã®ä¸‹ä½åˆ†é¡ï¼‰ã‚’ä»˜ä¸ã—ã¦ãã ã•ã„ã€‚
- å‡ºåŠ›ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã¨ã—ã¦ãã ã•ã„ã€‚

ã€æ§‹é€ åŒ–å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
{{
  "recommended_codes": [
    {{
      "code": "G01N 21/00",
      "reason": "ï¼ˆä¾‹ï¼šè¢«è†œã®ç‰©æ€§ï¼ˆæ¥è§¦è§’ãªã©ï¼‰ã‚’æ¸¬å®šã™ã‚‹æŠ€è¡“ã«é–¢é€£ï¼‰"
    }},
    {{
      "code": "H01L 21/00",
      "reason": "ï¼ˆä¾‹ï¼šåŠå°ä½“è£½é€ ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã‘ã‚‹é¡ä¼¼ã®è¢«è†œæŠ€è¡“ï¼‰"
    }},
    {{
      "code": "B05D 5/08",
      "reason": "ï¼ˆä¾‹ï¼šåŸºæ¿ã¸ã®ç‰¹å®šã®è¡¨é¢ç‰¹æ€§ï¼ˆæ’¥æ²¹æ€§ãªã©ï¼‰ã®ä»˜ä¸æŠ€è¡“ï¼‰"
    }}
  ]
}}
"""


# ==================== å…ƒã®ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹ (å¤‰æ›´ãªã—) ====================

class PatentExaminationSystemIntegrated:
    """çµ±åˆç‰ˆç‰¹è¨±å¯©æŸ»ã‚·ã‚¹ãƒ†ãƒ """

    # def __init__(self, api_key: str, model_name: str = "gemini-2.0-flash-exp"):
    def __init__(self, api_key: str, model_name: str = "gemini-2.0-flash"):
    # def __init__(self, api_key: str, model_name: str = "gemini-2.5-flash"):
        """
        Args:
            api_key: Google AI Studio APIã‚­ãƒ¼
            model_name: ä½¿ç”¨ã™ã‚‹Geminiãƒ¢ãƒ‡ãƒ«
        """
        if not api_key:
            raise ValueError("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚config.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        genai.configure(api_key=api_key)
        self.model_name = model_name
        self.model = genai.GenerativeModel(model_name)

        # JSONå‡ºåŠ›ç”¨ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ç”¨ï¼‰
        self.json_model = genai.GenerativeModel(
            model_name=model_name,
            generation_config={"response_mime_type": "application/json"}
        )

        # ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆæ–‡è„ˆä¿æŒç”¨ï¼‰
        self.chat = None
        self.conversation_history = []

    def _parse_json_response(self, response_text: str) -> Dict:
        """
        JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å …ç‰¢ã«ãƒ‘ãƒ¼ã‚¹

        Args:
            response_text: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸJSONè¾æ›¸
        """
        try:
            result = json.loads(response_text)
            # ãƒªã‚¹ãƒˆå½¢å¼ã§è¿”ã£ã¦ããŸå ´åˆã¯æœ€åˆã®è¦ç´ ã‚’å–å¾—
            if isinstance(result, list) and len(result) > 0:
                result = result[0]
            return result
        except json.JSONDecodeError:
            # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»ã—ã¦å†è©¦è¡Œ
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))
            else:
                # ```ãªã—ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚‚è©¦ã™
                json_match = re.search(r'```\s*(.*?)\s*```', response_text, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group(1))
                # æœ€å¾Œã®æ‰‹æ®µã¨ã—ã¦ç´ ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹
                return json.loads(response_text.strip())

    def _generate_with_retry(self, use_json_model: bool, prompt: str,
                            max_retries: int = 5, initial_wait: int = 2) -> str:
        """
        ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ä»˜ãã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ

        Args:
            use_json_model: JSONå‡ºåŠ›ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‹
            prompt: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
            initial_wait: åˆæœŸå¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰

        Returns:
            ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ
        """
        model = self.json_model if use_json_model else self.model

        for attempt in range(max_retries):
            try:
                if self.chat and not use_json_model:
                    # ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ï¼ˆæ–‡è„ˆä¿æŒï¼‰
                    response = self.chat.send_message(prompt)
                else:
                    # å˜ç™ºã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆJSONæ§‹é€ åŒ–ç”¨ï¼‰
                    response = model.generate_content(prompt)
                return response.text
            except google_exceptions.ResourceExhausted as e:
                if attempt < max_retries - 1:
                    wait_time = initial_wait * (4 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    print(f"\nâ³ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™... (è©¦è¡Œ {attempt + 1}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    print(f"\nâŒ æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {e}")
                    raise
            except Exception as e:
                print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
                raise

    # ... (step0_structure_application ã‹ã‚‰ save_results ã¾ã§ã®å…¨ãƒ¡ã‚½ãƒƒãƒ‰ã¯å¤‰æ›´ãªã—) ...
    def step0_structure_application(self, doc_dict: Dict) -> PatentDocument:
        """
        ã‚¹ãƒ†ãƒƒãƒ—0.1: æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–

        Args:
            abstract: æœ¬é¡˜ç™ºæ˜ã®Abstract
            claims: æœ¬é¡˜ç™ºæ˜ã®Claimãƒªã‚¹ãƒˆ

        Returns:
            æ§‹é€ åŒ–ã•ã‚ŒãŸæœ¬é¡˜ç™ºæ˜ãƒ‡ãƒ¼ã‚¿
        """
        print("=" * 80)
        print("ğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—0.1: æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–")
        print("=" * 80)

        abstract = doc_dict.get("abstract", "")
        claims_text = doc_dict.get("claims", "")

        prompt = PromptTemplates.STEP_0_1_STRUCTURE_APPLICATION.format(
            abstract=abstract,
            claims_text=claims_text
        )

        response_text = self._generate_with_retry(use_json_model=True, prompt=prompt)
        result = self._parse_json_response(response_text)

        print("\nâœ… æ§‹é€ åŒ–å®Œäº†:")
        print(f"èª²é¡Œ: {result['problem']}")
        print(f"è§£æ±ºåŸç†: {result['solution_principle']}")
        print(f"Claim 1è¦ä»¶: {len(result['claim1_requirements'])}å€‹")

        self.conversation_history.append({
            "step": doc_dict["step"],
            "role": "æ§‹é€ åŒ–",
            "content": result
        })

        return result


    def step1_applicant_arguments(self, app_data: Dict, prior_data: Dict) -> str:
        """
        ã‚¹ãƒ†ãƒƒãƒ—1: ä»£ç†äººã®æ®µéšçš„ä¸»å¼µ

        Args:
            app_data: æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿
            prior_data: å…ˆè¡ŒæŠ€è¡“ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿

        Returns:
            ä»£ç†äººã®ä¸»å¼µãƒ†ã‚­ã‚¹ãƒˆ
        """
        print("\n" + "=" * 80)
        print("âš–ï¸ ã‚¹ãƒ†ãƒƒãƒ—1: ä»£ç†äººã®æ®µéšçš„ä¸»å¼µ")
        print("=" * 80)

        prompt = PromptTemplates.STEP_1_APPLICANT_ARGUMENTS.format(
            app_data=json.dumps(app_data, ensure_ascii=False, indent=2),
            prior_data=json.dumps(prior_data, ensure_ascii=False, indent=2)
        )

        arguments = self._generate_with_retry(use_json_model=False, prompt=prompt)

        print("\nâœ… ä»£ç†äººã®ä¸»å¼µã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
        print("\n" + "-" * 80)
        print(arguments)
        print("-" * 80)

        self.conversation_history.append({
            "step": "1",
            "role": "ä»£ç†äºº",
            "content": arguments
        })

        return arguments

    def step2_examiner_review(self, app_data: Dict, prior_data: Dict, arguments: str) -> str:
        """
        ã‚¹ãƒ†ãƒƒãƒ—2: å¯©æŸ»å®˜ã®æ®µéšçš„æ‰¹è©•ï¼ˆ7è³ªå•ã«ã‚ˆã‚‹æ¤œè¨¼ï¼‰

        Args:
            app_data: æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿
            prior_data: å…ˆè¡ŒæŠ€è¡“ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿
            arguments: ä»£ç†äººã®ä¸»å¼µ

        Returns:
            å¯©æŸ»å®˜ã®æ¤œè¨¼ãƒ»åè«–ãƒ†ã‚­ã‚¹ãƒˆ
        """
        print("\n" + "=" * 80)
        print("ğŸ” ã‚¹ãƒ†ãƒƒãƒ—2: å¯©æŸ»å®˜ã®å°‚é–€çš„åˆ¤æ–­")
        print("=" * 80)

        prompt = PromptTemplates.STEP_2_EXAMINER_REVIEW.format(
            app_data=json.dumps(app_data, ensure_ascii=False, indent=2),
            prior_data=json.dumps(prior_data, ensure_ascii=False, indent=2),
            arguments=arguments
        )

        review = self._generate_with_retry(use_json_model=False, prompt=prompt)

        print("\nâœ… å¯©æŸ»å®˜ã®æ¤œè¨¼ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
        print("\n" + "-" * 80)
        print(review)
        print("-" * 80)

        self.conversation_history.append({
            "step": "2",
            "role": "å¯©æŸ»å®˜",
            "content": review
        })

        return review

    def step3_final_decision(self, arguments: str, review: str) -> str:
        """
        ã‚¹ãƒ†ãƒƒãƒ—3: ä¸»ä»»å¯©æŸ»å®˜ã®æ®µéšçš„çµ±åˆåˆ¤æ–­

        Args:
            arguments: ä»£ç†äººã®ä¸»å¼µ
            review: å¯©æŸ»å®˜ã®æ¤œè¨¼ãƒ»åè«–

        Returns:
            æœ€çµ‚åˆ¤æ–­ãƒ†ã‚­ã‚¹ãƒˆ
        """
        print("\n" + "=" * 80)
        print("âš–ï¸ ã‚¹ãƒ†ãƒƒãƒ—3: ä¸»ä»»å¯©æŸ»å®˜ã®æ®µéšçš„çµ±åˆåˆ¤æ–­")
        print("=" * 80)

        prompt = PromptTemplates.STEP_3_FINAL_DECISION.format(
            arguments=arguments,
            review=review
        )

        decision = self._generate_with_retry(use_json_model=False, prompt=prompt)

        print("\nâœ… æœ€çµ‚åˆ¤æ–­ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
        print("\n" + "=" * 80)
        print(decision)
        print("=" * 80)

        self.conversation_history.append({
            "step": "3",
            "role": "ä¸»ä»»å¯©æŸ»å®˜",
            "content": decision
        })

        return decision

    def run_full_examination(self,
                            dict_a: Dict,
                            dict_b: Dict) -> Dict:
        """
        å®Œå…¨ãªå¯©æŸ»ãƒ—ãƒ­ã‚»ã‚¹ã®å®Ÿè¡Œ

        Args:
            dict_a: æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿
            app_claims: æœ¬é¡˜ç™ºæ˜ã®Claimãƒªã‚¹ãƒˆ
            prior_abstract: å…ˆè¡ŒæŠ€è¡“ã®Abstract
            prior_claims: å…ˆè¡ŒæŠ€è¡“ã®Claimãƒªã‚¹ãƒˆ

        Returns:
            å¯©æŸ»çµæœã®è¾æ›¸
        """
        print("\n" + "ğŸš€" * 40)
        print("ç‰¹è¨±å¯©æŸ»ãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹ (çµ±åˆç‰ˆ)")
        print("ğŸš€" * 40)

        # ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ï¼ˆæ–‡è„ˆä¿æŒç”¨ï¼‰
        self.chat = self.model.start_chat(history=[])

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—0: æ§‹é€ åŒ–
            dict_a["step"] = "0.1 Claim"
            dict_b["step"] = "0.2 Candidate Prior Art"
            app_data = self.step0_structure_application(dict_a)
            prior_data = self.step0_structure_application(dict_b)

            # ã‚¹ãƒ†ãƒƒãƒ—1: ä»£ç†äººã®ä¸»å¼µ
            arguments = self.step1_applicant_arguments(app_data, prior_data)

            # ã‚¹ãƒ†ãƒƒãƒ—2: å¯©æŸ»å®˜ã®æ¤œè¨¼
            review = self.step2_examiner_review(app_data, prior_data, arguments)

            # ã‚¹ãƒ†ãƒƒãƒ—3: æœ€çµ‚åˆ¤æ–­
            decision = self.step3_final_decision(arguments, review)

            print("\n" + "âœ…" * 40)
            print("ç‰¹è¨±å¯©æŸ»ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†")
            print(decision)
            print("âœ…" * 40)

            inventiveness = self.judge_inventiveness(decision)

            return {
                "application_structure": app_data,
                "prior_art_structure": prior_data,
                "applicant_arguments": arguments,
                "examiner_review": review,
                "final_decision": decision,
                "conversation_history": self.conversation_history,
                "inventiveness": inventiveness
            }

        except Exception as e:
            print(f"\n--- ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ---")
            print(f"ã‚¨ãƒ©ãƒ¼å†…å®¹: {e}")
            # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã§ã‚‚éƒ¨åˆ†çš„ãªçµæœã‚’è¿”ã™
            return {
                "error": str(e),
                "conversation_history": self.conversation_history,
                "partial_results": "å‡¦ç†ãŒé€”ä¸­ã§ä¸­æ–­ã•ã‚Œã¾ã—ãŸ"
            }

    def judge_inventiveness(self, final_decision_text: str) -> Dict[str, bool]:
        """
        æœ€çµ‚åˆ¤æ–­ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å„ã‚¯ãƒ¬ãƒ¼ãƒ ã®é€²æ­©æ€§ã‚’æŠ½å‡º
        ã“ã®jsonãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦ã€jsonå½¢å¼ã§è¿”ã™ã€‚
        ```json
{
  "claim1": {
    "inventive": false,
    "reason": "ãƒ¬ã‚¤ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã«ãŠã‘ã‚‹å‡¦ç†é€Ÿåº¦å‘ä¸Šãƒ‹ãƒ¼ã‚ºã¯è‡ªæ˜ã§ã‚ã‚Šã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åˆ†å‰²ãƒ»ä¸¦åˆ—åŒ–ã¯é€šå¸¸ã®æœ€é©åŒ–æ‰‹æ®µã§ã‚ã‚‹ãŸã‚ã€‚"
  },
  "claim2": {
    "inventive": false,
    "reason": "Claim 1ã®ä¸¦åˆ—åŒ–ãŒå®¹æ˜“æƒ³åˆ°ã§ã‚ã‚‹å ´åˆã€å„ãƒ¦ãƒ‹ãƒƒãƒˆãŒç•°ãªã‚‹ãƒ¬ã‚¤ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ã¯ä¸¦åˆ—å‡¦ç†åŠ¹ç‡æœ€å¤§åŒ–ã®ãŸã‚ã®æŠ€è¡“å¸¸è­˜ã§ã‚ã‚‹ãŸã‚ã€‚"
  },
  "claim3": {
    "inventive": false,


        Args:
            final_decision_text: æœ€çµ‚åˆ¤æ–­ã®ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            å„ã‚¯ãƒ¬ãƒ¼ãƒ ã®é€²æ­©æ€§ã‚’ç¤ºã™è¾æ›¸

        """
        inventiveness = {}
        # â€™â€™â€™jsonå½¢å¼ã®éƒ¨åˆ†ã‚’æŠ½å‡º
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', final_decision_text, re.DOTALL)
        if json_match:
            json_text = json_match.group(1)
            try:
                json_data = json.loads(json_text)
                # claimã¯ä½•ç•ªã¾ã§ã‚ã‚‹ã‹ä¸æ˜ãªã®ã§ã€å‹•çš„ã«å‡¦ç†
                for claim_key in json_data.keys():
                    if claim_key.startswith("claim"):
                        inventiveness[claim_key] = {
                            'inventive': json_data[claim_key]['inventive'],
                            'reason': json_data[claim_key]['reason']
                        }
                return inventiveness
            except json.JSONDecodeError:
                print("âŒ æœ€çµ‚åˆ¤æ–­ã®JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                print(final_decision_text)
                return {"error": final_decision_text}



        for claim_num in range(1, 4):
            pattern = rf"### {claim_num}\. Claim {claim_num} .*?\n\*\*åˆ¤æ–­:\*\* \[(å®¹æ˜“æƒ³åˆ°ã§ã‚ã‚‹|å®¹æ˜“æƒ³åˆ°ã§ã¯ãªã„)\]"
            match = re.search(pattern, final_decision_text, re.DOTALL)
            if match:
                inventiveness[claim_num] = (match.group(1) == "å®¹æ˜“æƒ³åˆ°ã§ã¯ãªã„")
            else:
                inventiveness[claim_num] = None  # åˆ¤å®šã§ããªã‹ã£ãŸå ´åˆ

        return inventiveness
    def save_results(self, results: Dict, output_path: str):
        """
        å¯©æŸ»çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜

        Args:
            results: å¯©æŸ»çµæœã®è¾æ›¸
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")


# ==================== â˜…â˜…â˜… æ–°ã—ã„å®Ÿé¨“ç”¨ã‚¯ãƒ©ã‚¹ â˜…â˜…â˜… ====================

class PatentSearchExpander:
    """
    AIãƒ¢ãƒ‡ãƒ«2, 3, 4ã‚’å®Ÿè¡Œã—ã€ç‰¹è¨±èª¿æŸ»ã‚¯ã‚¨ãƒªã‚’æ‹¡å¼µã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¹
    """

    def __init__(self, api_key: str, model_name: str = "gemini-2.0-flash"):
        """
        Args:
            api_key: Google AI Studio APIã‚­ãƒ¼
            model_name: ä½¿ç”¨ã™ã‚‹Geminiãƒ¢ãƒ‡ãƒ«
        """
        if not api_key:
            raise ValueError("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚config.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        genai.configure(api_key=api_key)
        self.model_name = model_name

        # JSONå‡ºåŠ›ç”¨ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆå…¨ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ã§JSONã‚’æœŸå¾…ã™ã‚‹ãŸã‚ï¼‰
        self.json_model = genai.GenerativeModel(
            model_name=model_name,
            generation_config={"response_mime_type": "application/json"}
        )

    def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
        """
        JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å …ç‰¢ã«ãƒ‘ãƒ¼ã‚¹ (PatentExaminationSystemIntegratedã‹ã‚‰æµç”¨)
        """
        try:
            result = json.loads(response_text)
            return result
        except json.JSONDecodeError:
            # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»ã—ã¦å†è©¦è¡Œ
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))
            else:
                json_match = re.search(r'```\s*(.*?)\s*```', response_text, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group(1))
                return json.loads(response_text.strip())

    def _generate_with_retry(self, prompt: str,
                            max_retries: int = 5, initial_wait: int = 2) -> str:
        """
        ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ä»˜ãã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ (JSONãƒ¢ãƒ‡ãƒ«å°‚ç”¨)
        """
        for attempt in range(max_retries):
            try:
                # å¸¸ã«JSONãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
                response = self.json_model.generate_content(prompt)
                return response.text
            except google_exceptions.ResourceExhausted as e:
                if attempt < max_retries - 1:
                    wait_time = initial_wait * (4 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    print(f"\nâ³ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™... (è©¦è¡Œ {attempt + 1}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    print(f"\nâŒ æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {e}")
                    raise
            except Exception as e:
                print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
                raise

    def run_model_2_decompose(self, claims_text: str) -> List[str]:
        """
        AIãƒ¢ãƒ‡ãƒ«2ï¼ˆåˆ†è§£ï¼‰: è«‹æ±‚é …ã‹ã‚‰æ§‹æˆè¦ç´ ã‚’æŠ½å‡ºã™ã‚‹
        """
        print("\n" + "=" * 80)
        print("ğŸ¤– AIãƒ¢ãƒ‡ãƒ«2: æ§‹æˆè¦ç´ ã®åˆ†è§£")
        print("=" * 80)
        prompt = PromptTemplates.MODEL_2_DECOMPOSE.format(claims_text=claims_text)
        
        response_text = self._generate_with_retry(prompt=prompt)
        parsed_json = self._parse_json_response(response_text)
        
        components = parsed_json.get("components", [])
        print(f"âœ… {len(components)}å€‹ã®æ§‹æˆè¦ç´ ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")
        for i, comp in enumerate(components):
            print(f"  [{i+1}] {comp}")
            
        return components

    def run_model_3_classify_elements(self, components: List[str]) -> Dict[str, List[str]]:
        """
        AIãƒ¢ãƒ‡ãƒ«3ï¼ˆè¦ç´ åˆ†é¡ï¼‰: å„æ§‹æˆè¦ç´ ã«é–¢é€£ã™ã‚‹åˆ†é¡ã‚³ãƒ¼ãƒ‰ã‚’äºˆæ¸¬ã™ã‚‹
        """
        print("\n" + "=" * 80)
        print("ğŸ¤– AIãƒ¢ãƒ‡ãƒ«3: æ§‹æˆè¦ç´ ã®åˆ†é¡")
        print("=" * 80)
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        components_list_str = "\n".join([f"- {c}" for c in components])
        
        prompt = PromptTemplates.MODEL_3_CLASSIFY_ELEMENTS.format(
            components_list=components_list_str
        )
        
        response_text = self._generate_with_retry(prompt=prompt)
        parsed_json = self._parse_json_response(response_text)
        
        classifications = parsed_json.get("component_classifications", [])
        
        # æ‰±ã„ã‚„ã™ã„ã‚ˆã†ã« Dict[str, List[str]] å½¢å¼ã«å¤‰æ›
        result_dict = {}
        print("âœ… æ§‹æˆè¦ç´ ã”ã¨ã®åˆ†é¡ã‚³ãƒ¼ãƒ‰ã‚’äºˆæ¸¬ã—ã¾ã—ãŸã€‚")
        for item in classifications:
            comp = item.get("component")
            codes = item.get("predicted_codes", [])
            if comp:
                result_dict[comp] = codes
                print(f"  â–¶ {comp}: {codes}")
                
        return result_dict

    def run_model_4_expand_search(self, all_class_codes: List[str]) -> List[Dict[str, str]]:
        """
        AIãƒ¢ãƒ‡ãƒ«4ï¼ˆæ¢ç´¢æ‹¡å¼µï¼‰: æ—¢çŸ¥ã®åˆ†é¡ã‚³ãƒ¼ãƒ‰ã‹ã‚‰é–¢é€£ã‚³ãƒ¼ãƒ‰ã‚’æ¨è–¦ã™ã‚‹
        """
        print("\n" + "=" * 80)
        print("ğŸ¤– AIãƒ¢ãƒ‡ãƒ«4: æ¤œç´¢ã‚¯ã‚¨ãƒªã®æ‹¡å¼µ")
        print("=" * 80)
        
        # é‡è¤‡ã‚’é™¤å»ã—ãŸã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        unique_codes = sorted(list(set(all_class_codes)))
        class_codes_list_str = "\n".join([f"- {c}" for c in unique_codes])
        
        print(f"å…¥åŠ›ã‚³ãƒ¼ãƒ‰ ({len(unique_codes)}ä»¶): {unique_codes}")
        
        prompt = PromptTemplates.MODEL_4_EXPAND_SEARCH.format(
            class_codes_list=class_codes_list_str
        )
        
        response_text = self._generate_with_retry(prompt=prompt)
        parsed_json = self._parse_json_response(response_text)
        
        recommended_codes = parsed_json.get("recommended_codes", [])
        print(f"\nâœ… {len(recommended_codes)}ä»¶ã®é–¢é€£ã‚³ãƒ¼ãƒ‰ã‚’æ¨è–¦ã—ã¾ã—ãŸã€‚")
        for item in recommended_codes:
            print(f"  â–¶ {item.get('code')}: {item.get('reason')}")
            
        return recommended_codes

    def run_full_expansion(self, 
                           claims_text: str, 
                           invention_class_codes: List[str] = None) -> Dict[str, Any]:
        """
        ãƒ¢ãƒ‡ãƒ«2, 3, 4ã‚’é †ç•ªã«å®Ÿè¡Œã—ã€æ¤œç´¢ã‚¯ã‚¨ãƒªæ‹¡å¼µã®å…¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹
        
        Args:
            claims_text: æœ¬é¡˜ç™ºæ˜ã®è«‹æ±‚é …ãƒ†ã‚­ã‚¹ãƒˆ
            invention_class_codes: (ã‚ªãƒ—ã‚·ãƒ§ãƒ³) AIãƒ¢ãƒ‡ãƒ«1ã§äºˆæ¸¬ã•ã‚ŒãŸç™ºæ˜è‡ªä½“ã®åˆ†é¡ã‚³ãƒ¼ãƒ‰
        
        Returns:
            å®Ÿé¨“çµæœã®å…¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ ¼ç´ã—ãŸè¾æ›¸
        """
        
        if invention_class_codes is None:
            invention_class_codes = []
            
        print("\n" + "ğŸš€" * 40)
        print("ç‰¹è¨±èª¿æŸ»ã‚¯ã‚¨ãƒªæ‹¡å¼µãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹")
        print("ğŸš€" * 40)
        
        results = {
            "model_1_input_codes": invention_class_codes,
            "model_2_components": [],
            "model_3_classifications": {},
            "model_4_recommendations": []
        }
        
        try:
            # AIãƒ¢ãƒ‡ãƒ«2: åˆ†è§£
            components = self.run_model_2_decompose(claims_text)
            results["model_2_components"] = components
            
            if not components:
                print("âš ï¸ ãƒ¢ãƒ‡ãƒ«2ã§æ§‹æˆè¦ç´ ãŒæŠ½å‡ºã•ã‚Œãªã‹ã£ãŸãŸã‚ã€ä»¥é™ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return results

            # AIãƒ¢ãƒ‡ãƒ«3: è¦ç´ åˆ†é¡
            classifications = self.run_model_3_classify_elements(components)
            results["model_3_classifications"] = classifications
            
            # AIãƒ¢ãƒ‡ãƒ«4ã¸ã®å…¥åŠ›ã‚³ãƒ¼ãƒ‰ã‚’æº–å‚™
            all_codes = list(invention_class_codes) # ãƒ¢ãƒ‡ãƒ«1ã®ã‚³ãƒ¼ãƒ‰
            for codes_list in classifications.values():
                all_codes.extend(codes_list) # ãƒ¢ãƒ‡ãƒ«3ã®ã‚³ãƒ¼ãƒ‰
                
            if not all_codes:
                print("âš ï¸ ãƒ¢ãƒ‡ãƒ«1ãŠã‚ˆã³3ã§åˆ†é¡ã‚³ãƒ¼ãƒ‰ãŒä¸€åˆ‡å¾—ã‚‰ã‚Œãªã‹ã£ãŸãŸã‚ã€ãƒ¢ãƒ‡ãƒ«4ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                return results

            # AIãƒ¢ãƒ‡ãƒ«4: æ¢ç´¢æ‹¡å¼µ
            recommendations = self.run_model_4_expand_search(all_codes)
            results["model_4_recommendations"] = recommendations
            
            print("\n" + "âœ…" * 40)
            print("ç‰¹è¨±èª¿æŸ»ã‚¯ã‚¨ãƒªæ‹¡å¼µãƒ—ãƒ­ã‚»ã‚¹å®Œäº†")
            print("âœ…" * 40)
            
            return results

        except Exception as e:
            print(f"\n--- ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ ---")
            print(f"ã‚¨ãƒ©ãƒ¼å†…å®¹: {e}")
            results["error"] = str(e)
            return results

# ==================== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•° (å¤‰æ›´ãªã—) ====================

def entry(doc_dict_a, doc_dict_b):
    """
    2ã¤ã®ã‚¯ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‰¹è¨±å¯©æŸ»ã‚’å®Ÿè¡Œã—ã€çµæœã‚’è¿”ã™
    (å…ƒã® PatentExaminationSystemIntegrated ã‚’å‘¼ã³å‡ºã™)
    """
    try:
        load_dotenv('config.env')
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print("âš ï¸ config.envãƒ•ã‚¡ã‚¤ãƒ«ã«GOOGLE_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„")
            return None

        # å…ƒã®å¯©æŸ»ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
        system = PatentExaminationSystemIntegrated(api_key)
        results = system.run_full_examination(doc_dict_a, doc_dict_b)   
        return results

    except ValueError as e:
        print(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

# ==================== â˜…â˜…â˜… æ–°ã—ã„å®Ÿé¨“ç”¨å®Ÿè¡Œé–¢æ•° â˜…â˜…â˜… ====================

def run_search_expansion_experiment():
    """
    æ–°ã—ã„ PatentSearchExpander ã‚¯ãƒ©ã‚¹ã‚’ä½¿ã£ãŸå®Ÿé¨“ã‚’å®Ÿè¡Œã™ã‚‹
    """
    try:
        load_dotenv('config.env')
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print("âš ï¸ config.envãƒ•ã‚¡ã‚¤ãƒ«ã«GOOGLE_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„")
            return None

        # æ–°ã—ã„æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
        expander = PatentSearchExpander(api_key)

        # --- ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ (å®Ÿé¨“ç”¨ã«æ›¸ãæ›ãˆã¦ãã ã•ã„) ---
        
        # AIãƒ¢ãƒ‡ãƒ«1 (åˆ†é¡) ã®çµæœï¼ˆä»®ï¼‰
        model_1_results = ["B41J 2/00", "C09D 11/00"]
        
        # AIãƒ¢ãƒ‡ãƒ«2 (åˆ†è§£) ã®å…¥åŠ›ã¨ãªã‚‹è«‹æ±‚é …ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä»®ï¼‰
        claims_text_input = """
ã€è«‹æ±‚é …ï¼‘ã€‘
ã‚¤ãƒ³ã‚¯æ»´ã‚’åå‡ºã™ã‚‹ãŸã‚ã®è¤‡æ•°ã®ãƒã‚ºãƒ«ãŒå½¢æˆã•ã‚ŒãŸãƒã‚ºãƒ«ãƒ—ãƒ¬ãƒ¼ãƒˆã¨ã€
å‰è¨˜ãƒã‚ºãƒ«ãƒ—ãƒ¬ãƒ¼ãƒˆã®è¡¨é¢ã«å½¢æˆã•ã‚ŒãŸè¢«è†œã¨ã€ã‚’å‚™ãˆã€
å‰è¨˜è¢«è†œã¯ã€ï¼“ï¼ï¼â„ƒã®æ¸©åº¦ã§ï¼‘ï¼•ï¼…æœªæº€ã®é‡é‡æå¤±ã‚’ç¤ºã—ã€
ç´„ï¼•ï¼Â°ã‚’è¶…ãˆã‚‹æ°´æ¥è§¦è§’åº¦ã¨ã€ç´„ï¼“ï¼Â°æœªæº€ã®æ»‘èµ°è§’åº¦ã‚’æœ‰ã—ã€
ï¼’ï¼™ï¼â„ƒã‹ã¤ï¼“ï¼•ï¼ï½ï½“ï½‰ã®ç’°å¢ƒã«æ›éœ²ã•ã‚ŒãŸå¾Œã‚‚å‰è¨˜ç‰¹æ€§ã‚’ç¶­æŒã™ã‚‹ã€
ã‚¤ãƒ³ã‚¯ã‚¸ã‚§ãƒƒãƒˆãƒ—ãƒªãƒ³ãƒˆãƒ˜ãƒƒãƒ‰ã€‚

ã€è«‹æ±‚é …ï¼’ã€‘
å‰è¨˜è¢«è†œãŒãƒ•ãƒƒç´ ç³»ãƒãƒªãƒãƒ¼ã‚’å«ã‚€ã€ã“ã¨ã‚’ç‰¹å¾´ã¨ã™ã‚‹è«‹æ±‚é …ï¼‘ã«è¨˜è¼‰ã®ã‚¤ãƒ³ã‚¯ã‚¸ã‚§ãƒƒãƒˆãƒ—ãƒªãƒ³ãƒˆãƒ˜ãƒƒãƒ‰ã€‚
"""
        # --- ã“ã“ã¾ã§ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ ---

        # å®Ÿé¨“å®Ÿè¡Œ
        results = expander.run_full_expansion(
            claims_text=claims_text_input,
            invention_class_codes=model_1_results
        )
        
        print("\n--- æœ€çµ‚å®Ÿé¨“çµæœ (JSON) ---")
        print(json.dumps(results, ensure_ascii=False, indent=2))
        
        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚ä¿å­˜
        output_path = "search_expansion_results.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ å®Ÿé¨“çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")

        return results

    except ValueError as e:
        print(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

    
if __name__ == "__main__":
    # --- â˜…â˜…â˜… ã“ã¡ã‚‰ã®å®Ÿé¨“ã‚’å®Ÿè¡Œã—ã¾ã™ â˜…â˜…â˜… ---
    run_search_expansion_experiment()
    
    # --- å…ƒã®é€²æ­©æ€§åˆ¤æ–­ã‚’å®Ÿè¡Œã—ãŸã„å ´åˆã¯ã€ä»¥ä¸‹ã‚’ã‚³ãƒ¡ãƒ³ãƒˆè§£é™¤ ---
    # print("ï¼ˆé€²æ­©æ€§åˆ¤æ–­ã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ï¼‰")
    # pass