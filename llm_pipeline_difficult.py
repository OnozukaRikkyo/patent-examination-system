"""
ç‰¹è¨±å¯©æŸ»ã®æ®µéšçš„é€²æ­©æ€§åˆ¤æ–­ã‚·ã‚¹ãƒ†ãƒ  (RAGçµ±åˆç‰ˆ)
ææ¡ˆã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«åŸºã¥ãå®Ÿè£…:
- ã‚¹ãƒ†ãƒƒãƒ—1: æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–
- ã‚¹ãƒ†ãƒƒãƒ—2: å¯¾æ¯”ç”¨RAGï¼ˆå…ˆè¡ŒæŠ€è¡“1ã‹ã‚‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆæŠ½å‡ºï¼‰
- ã‚¹ãƒ†ãƒƒãƒ—3: LLMã«ã‚ˆã‚‹å¯¾æ¯”è¡¨ä½œæˆ
- ã‚¹ãƒ†ãƒƒãƒ—4: æ–°è¦æ€§åˆ¤å®šã¨ç›¸é•ç‚¹ç¢ºå®š
- ã‚¹ãƒ†ãƒƒãƒ—5: å‹•æ©Ÿä»˜ã‘æ¤œç´¢ï¼ˆRAGï¼‰
- ã‚¹ãƒ†ãƒƒãƒ—6: é€²æ­©æ€§ã®ä»®åˆ¤å®šã¨è‡ªä¿¡åº¦è©•ä¾¡
- ã‚¹ãƒ†ãƒƒãƒ—7: äººé–“ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›
"""

import google.generativeai as genai
import os
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
import json
from dotenv import load_dotenv
import time
from google.api_core import exceptions as google_exceptions
import re


# ==================== ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹å®šç¾© ====================

@dataclass
class PatentDocument:
    """ç‰¹è¨±æ–‡çŒ®ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿"""
    problem: str
    solution_principle: str
    claim1_requirements: List[str]


@dataclass
class NoveltyReport:
    """æ–°è¦æ€§åˆ¤å®šãƒ¬ãƒãƒ¼ãƒˆ"""
    novelty_judgement: str  # "ã‚ã‚Š" or "ãªã—"
    difference_points: List[str]


@dataclass
class InventiveStepReport:
    """é€²æ­©æ€§åˆ¤å®šãƒ¬ãƒãƒ¼ãƒˆ"""
    judgement: str  # "é€²æ­©æ€§ã‚ã‚Š" or "é€²æ­©æ€§ãªã—" or "åˆ¤æ–­å›°é›£"
    confidence: str  # "é«˜" or "ä¸­" or "ä½"
    rationale: str
    low_confidence_points: List[str]


# ==================== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ ====================

class PromptTemplates:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    # ã‚¹ãƒ†ãƒƒãƒ—1: æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–
    STEP1_STRUCTURE_APPLICATION = """ä»¥ä¸‹ã®ã€Œæœ¬é¡˜ç™ºæ˜ã€ã®AbstractãŠã‚ˆã³å…¨ã¦ã®Claimã‚’èª­ã¿ã€ç‰¹è¨±åˆ¤æ–­ã«å¿…è¦ãªè¦ç´ ã‚’ä»¥ä¸‹ã®JSONå½¢å¼ã§æŠ½å‡ºãƒ»æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ã€‚

ã€æœ¬é¡˜ç™ºæ˜ãƒ†ã‚­ã‚¹ãƒˆã€‘
{application_text}

ã€æ§‹é€ åŒ–å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
```json
{{
  "problem": "èª²é¡Œï¼ˆä¾‹ï¼šãƒã‚ºãƒ«ãƒ—ãƒ¬ãƒ¼ãƒˆã®æ©Ÿæ¢°çš„é ‘å¼·æ€§ã®å‘ä¸Šï¼‰",
  "solution_principle": "è§£æ±ºåŸç†ï¼ˆä¾‹ï¼šé«˜ç†±å®‰å®šæ€§ãƒ»ç‰¹å®šã®ç‰©æ€§ã‚’æŒã¤ç–æ²¹æ€§è¢«è†œã®é©ç”¨ï¼‰",
  "claim1_requirements": [
    "è¦ä»¶A: ï¼ˆä¾‹ï¼šæœ€é«˜300â„ƒã§15%æœªæº€ã®é‡é‡æå¤±ï¼‰",
    "è¦ä»¶B: ï¼ˆä¾‹ï¼šæ¥è§¦è§’åº¦ ç´„50Â°è¶…ï¼‰",
    "è¦ä»¶C: ï¼ˆä¾‹ï¼šæ»‘èµ°è§’åº¦ ç´„30Â°æœªæº€ï¼‰"
  ]
}}
```

JSONå½¢å¼ã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""

    # ã‚¹ãƒ†ãƒƒãƒ—3: å¯¾æ¯”è¡¨ï¼ˆã‚¯ãƒ¬ãƒ¼ãƒ ãƒãƒ£ãƒ¼ãƒˆï¼‰ã®ä½œæˆ
    STEP3_CLAIM_CHART = """ã‚ãªãŸã¯ã€ç‰¹è¨±åˆ†æã‚’æ”¯æ´ã™ã‚‹å„ªç§€ãªãƒ‘ãƒ©ãƒªãƒ¼ã‚¬ãƒ«ã§ã™ã€‚
ä»¥ä¸‹ã®ã€æœ¬é¡˜ç™ºæ˜ã®æ§‹æˆè¦ä»¶ã€‘ã¨ã€å…ˆè¡ŒæŠ€è¡“1ã®é–¢é€£æŠœç²‹ã€‘ã‚’å³å¯†ã«æ¯”è¼ƒã—ã€æ³•çš„åˆ¤æ–­ï¼ˆæ–°è¦æ€§ãƒ»é€²æ­©æ€§ã®æœ‰ç„¡ï¼‰ã¯ä¸€åˆ‡è¡Œã‚ãšã€**äº‹å®Ÿã®å¯¾æ¯”ã®ã¿**ã‚’è¡Œã£ãŸã€Œå¯¾æ¯”è¡¨ï¼ˆã‚¯ãƒ¬ãƒ¼ãƒ ãƒãƒ£ãƒ¼ãƒˆï¼‰ã€ã‚’Markdownå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚

* ã€Œå…ˆè¡ŒæŠ€è¡“1ã®å¯¾å¿œè¨˜è¼‰ã€åˆ—ã«ã¯ã€ã€å…ˆè¡ŒæŠ€è¡“1ã®é–¢é€£æŠœç²‹ã€‘ã‹ã‚‰æœ€ã‚‚é–¢é€£ã™ã‚‹è¨˜è¿°ã‚’**æ­£ç¢ºã«å¼•ç”¨**ã—ã¦ãã ã•ã„ã€‚
* ã‚‚ã—ã€å…ˆè¡ŒæŠ€è¡“1ã®é–¢é€£æŠœç²‹ã€‘ã®ä¸­ã«ã€è©²å½“ã™ã‚‹è¨˜è¿°ãŒè¦‹å½“ãŸã‚‰ãªã„å ´åˆã¯ã€æ˜ç¢ºã«ã€Œ**è¨˜è¼‰ãªã—**ã€ã¨è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚

-----

**ã€æœ¬é¡˜ç™ºæ˜ã®æ§‹æˆè¦ä»¶ã€‘:**
```json
{claim1_requirements}
```

**ã€å…ˆè¡ŒæŠ€è¡“1ã®é–¢é€£æŠœç²‹ã€‘:**
```text
{prior_art_snippets}
```

-----

**ã€å‡ºåŠ›ï¼šå¯¾æ¯”è¡¨ã€‘**
ä»¥ä¸‹ã®Markdownãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

| æœ¬é¡˜ç™ºæ˜ã®è¦ä»¶ | å…ˆè¡ŒæŠ€è¡“1ã®å¯¾å¿œè¨˜è¼‰ï¼ˆå¼•ç”¨ï¼‰ | ä¸€è‡´/ç›¸é• |
| :--- | :--- | :--- |
| ... | ... | ... |"""

    # ã‚¹ãƒ†ãƒƒãƒ—4: æ–°è¦æ€§ã®åˆ¤å®šã¨ç›¸é•ç‚¹ã®ç¢ºå®š
    STEP4_NOVELTY_JUDGEMENT = """ã‚ãªãŸã¯ç‰¹è¨±å¯©æŸ»å®˜ã§ã™ã€‚
ä»¥ä¸‹ã®ã€å¯¾æ¯”è¡¨ã€‘ã‚’èª­ã¿ã€æœ¬é¡˜ç™ºæ˜ã®ã€Œæ–°è¦æ€§ã€ã®æœ‰ç„¡ã‚’æ©Ÿæ¢°çš„ã«åˆ¤å®šã—ã€ã€Œç›¸é•ç‚¹ã€ã‚’æ­£ç¢ºã«ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚

**åˆ¤å®šãƒ«ãƒ¼ãƒ«:**
1. ã€Œä¸€è‡´/ç›¸é•ã€åˆ—ã«ã€Œç›¸é•ã€ãŒ1ã¤ã§ã‚‚å­˜åœ¨ã™ã‚‹å ´åˆã€æ–°è¦æ€§ã¯ã€Œã‚ã‚Šã€ã§ã™ã€‚
2. ã™ã¹ã¦ã®è¦ä»¶ãŒã€Œä¸€è‡´ã€ã¾ãŸã¯ã€Œå®Ÿè³ªä¸€è‡´ã€ã®å ´åˆã€æ–°è¦æ€§ã¯ã€Œãªã—ã€ã§ã™ã€‚

**ã€å¯¾æ¯”è¡¨ã€‘:**
```markdown
{claim_chart}
```

**ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆJSONï¼‰ã€‘:**
```json
{{
  "novelty_judgement": "ã‚ã‚Š" | "ãªã—",
  "difference_points": [
    "ï¼ˆã€Œç›¸é•ã€ã¨åˆ¤å®šã•ã‚ŒãŸè¦ä»¶ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã“ã“ã«è¨˜è¼‰ï¼‰"
  ]
}}
```

JSONå½¢å¼ã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""

    # ã‚¹ãƒ†ãƒƒãƒ—6: é€²æ­©æ€§ã®ä»®åˆ¤å®šã¨è‡ªä¿¡åº¦è©•ä¾¡
    STEP6_INVENTIVE_STEP = """ã‚ãªãŸã¯ã€ç‰¹è¨±å¯©æŸ»å®˜ï¼ˆè¨“ç·´ä¸­ï¼‰ã§ã™ã€‚
ä»¥ä¸‹ã®ã€è¨¼æ‹ ãƒªã‚¹ãƒˆã€‘ã«åŸºã¥ãã€æœ¬é¡˜ç™ºæ˜ï¼ˆã‚¯ãƒ¬ãƒ¼ãƒ 1ï¼‰ã®ã€Œé€²æ­©æ€§ã€ã«ã¤ã„ã¦ä»®åˆ¤å®šã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã€è¨¼æ‹ ãƒªã‚¹ãƒˆã€‘
* **è¨¼æ‹ 1 (æœ¬é¡˜ç™ºæ˜):**
```json
{application_data}
```

* **è¨¼æ‹ 2 (å…ˆè¡ŒæŠ€è¡“1ã¨ã®å¯¾æ¯”):**
```markdown
{claim_chart}
```

* **è¨¼æ‹ 3 (ç›¸é•ç‚¹):**
```json
{difference_points}
```

* **è¨¼æ‹ 4 (ä»–ã®å…ˆè¡ŒæŠ€è¡“ã‹ã‚‰ã®ç¤ºå”†):**
```text
{motivation_snippets}
```

-----

ã€ã‚¿ã‚¹ã‚¯ã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã§ã€Œé€²æ­©æ€§ä»®åˆ¤å®šãƒ¬ãƒãƒ¼ãƒˆã€ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

```json
{{
  "judgement": "é€²æ­©æ€§ã‚ã‚Š" | "é€²æ­©æ€§ãªã—" | "åˆ¤æ–­å›°é›£",
  "confidence": "é«˜" | "ä¸­" | "ä½",
  "rationale": "ï¼ˆãªãœãã®ã‚ˆã†ã«åˆ¤å®šã—ãŸã‹ã®å…·ä½“çš„æ ¹æ‹ ã€‚è¨¼æ‹ 4ã®å¼•ç”¨ã‚’å«ã‚€ï¼‰",
  "low_confidence_points": [
    "ï¼ˆè‡ªä¿¡åº¦ãŒã€Œä¸­ã€ã¾ãŸã¯ã€Œä½ã€ã®å ´åˆã€åˆ¤æ–­ã‚’è¿·ã‚ã›ã¦ã„ã‚‹è¦å› ã‚„ã€è¿½åŠ èª¿æŸ»ãŒå¿…è¦ãªç‚¹ã‚’å…·ä½“çš„ã«è¨˜è¿°ã™ã‚‹ã€‚ï¼‰"
  ]
}}
```

JSONå½¢å¼ã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""


# ==================== RAGã‚·ã‚¹ãƒ†ãƒ ï¼ˆç°¡æ˜“ç‰ˆï¼‰====================

class SimpleRAGSystem:
    """
    ç°¡æ˜“çš„ãªRAGã‚·ã‚¹ãƒ†ãƒ 
    å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€Chroma/Pinecone/FAISSãªã©ã®ãƒ™ã‚¯ãƒˆãƒ«DBã‚’ä½¿ç”¨
    """

    def __init__(self):
        self.documents = {}  # doc_id -> full_text
        self.chunks = {}  # chunk_id -> (doc_id, chunk_text)

    def index_document(self, doc_id: str, full_text: str, chunk_size: int = 500):
        """
        æ–‡æ›¸ã‚’ãƒãƒ£ãƒ³ã‚¯åŒ–ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        
        Args:
            doc_id: æ–‡æ›¸ID
            full_text: æ–‡æ›¸å…¨æ–‡
            chunk_size: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆæ–‡å­—æ•°ï¼‰
        """
        self.documents[doc_id] = full_text
        
        # ç°¡æ˜“çš„ãªãƒãƒ£ãƒ³ã‚¯åŒ–ï¼ˆæ®µè½ãƒ™ãƒ¼ã‚¹ï¼‰
        paragraphs = full_text.split('\n\n')
        chunk_id = 0
        for para in paragraphs:
            if para.strip():
                self.chunks[f"{doc_id}_chunk_{chunk_id}"] = (doc_id, para.strip())
                chunk_id += 1

    def search(self, queries: List[str], top_k: int = 5) -> str:
        """
        ã‚¯ã‚¨ãƒªã«é–¢é€£ã™ã‚‹ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æ¤œç´¢
        
        Args:
            queries: æ¤œç´¢ã‚¯ã‚¨ãƒªã®ãƒªã‚¹ãƒˆ
            top_k: å„ã‚¯ã‚¨ãƒªã§å–å¾—ã™ã‚‹ä¸Šä½ä»¶æ•°
            
        Returns:
            çµ±åˆã•ã‚ŒãŸã‚¹ãƒ‹ãƒšãƒƒãƒˆãƒ†ã‚­ã‚¹ãƒˆ
        """
        # ç°¡æ˜“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ï¼ˆå®Ÿéš›ã¯ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’ä½¿ç”¨ï¼‰
        all_snippets = set()
        
        for query in queries:
            keywords = query.lower().split()
            scored_chunks = []
            
            for chunk_id, (doc_id, chunk_text) in self.chunks.items():
                score = sum(1 for keyword in keywords if keyword in chunk_text.lower())
                if score > 0:
                    scored_chunks.append((score, chunk_id, chunk_text))
            
            # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
            scored_chunks.sort(reverse=True, key=lambda x: x[0])
            
            # Top-kä»¶ã‚’å–å¾—
            for _, _, chunk_text in scored_chunks[:top_k]:
                all_snippets.add(chunk_text)
        
        return "\n...\n".join(all_snippets)


# ==================== ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹ ====================

class PatentExaminationSystemRAG:
    """RAGçµ±åˆç‰ˆç‰¹è¨±å¯©æŸ»ã‚·ã‚¹ãƒ†ãƒ """

#    def __init__(self, api_key: str, model_name: str = "gemini-2.0-flash-exp"):
    def __init__(self, api_key: str, model_name: str = "gemini-2.5-pro"):
        """
        Args:
            api_key: Google AI Studio APIã‚­ãƒ¼
            model_name: ä½¿ç”¨ã™ã‚‹Geminiãƒ¢ãƒ‡ãƒ«
        """
        if not api_key:
            raise ValueError("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

        genai.configure(api_key=api_key)
        self.model_name = model_name
        self.model = genai.GenerativeModel(model_name)

        # JSONå‡ºåŠ›ç”¨ã®ãƒ¢ãƒ‡ãƒ«
        self.json_model = genai.GenerativeModel(
            model_name=model_name,
            generation_config={"response_mime_type": "application/json"}
        )

        # RAGã‚·ã‚¹ãƒ†ãƒ 
        self.rag_system = SimpleRAGSystem()
        
        # å‡¦ç†å±¥æ­´
        self.processing_history = []

    def _generate_with_retry(self, use_json_model: bool, prompt: str, 
                            max_retries: int = 3) -> str:
        """
        ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã§LLMã‚’å‘¼ã³å‡ºã™
        
        Args:
            use_json_model: JSONå‡ºåŠ›ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‹
            prompt: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
            max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        model = self.json_model if use_json_model else self.model
        
        for attempt in range(max_retries):
            try:
                response = model.generate_content(prompt)
                return response.text
            except google_exceptions.ResourceExhausted:
                wait_time = (attempt + 1) * 5
                print(f"âš ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¾ã™...")
                time.sleep(wait_time)
            except Exception as e:
                print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼ˆè©¦è¡Œ {attempt + 1}/{max_retries}ï¼‰: {e}")
                if attempt == max_retries - 1:
                    raise
                time.sleep(2)
        
        raise Exception("æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’è¶…ãˆã¾ã—ãŸ")

    def _parse_json_response(self, response_text: str) -> Dict:
        """
        JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å …ç‰¢ã«ãƒ‘ãƒ¼ã‚¹
        
        Args:
            response_text: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸJSONè¾æ›¸
        """
        try:
            result = json.loads(response_text)
            if isinstance(result, list) and len(result) > 0:
                result = result[0]
            return result
        except json.JSONDecodeError:
            # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»ã—ã¦å†è©¦è¡Œ
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))
            else:
                json_match = re.search(r'```\s*(.*?)\s*```', response_text, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group(1))
                return json.loads(response_text.strip())

    def step1_structure_application(self, application_text: str) -> Dict:
        """
        ã‚¹ãƒ†ãƒƒãƒ—1: æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–
        
        Args:
            application_text: æœ¬é¡˜ç™ºæ˜ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆAbstract + Claimsï¼‰
            
        Returns:
            æ§‹é€ åŒ–ã•ã‚ŒãŸJSONè¾æ›¸
        """
        print("\n" + "=" * 80)
        print("ğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—1: æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–")
        print("=" * 80)

        prompt = PromptTemplates.STEP1_STRUCTURE_APPLICATION.format(
            application_text=application_text
        )

        response_text = self._generate_with_retry(use_json_model=True, prompt=prompt)
        result = self._parse_json_response(response_text)

        print("\nâœ… æ§‹é€ åŒ–å®Œäº†:")
        print(f"èª²é¡Œ: {result['problem']}")
        print(f"è§£æ±ºåŸç†: {result['solution_principle']}")
        print(f"Claim 1è¦ä»¶: {len(result['claim1_requirements'])}å€‹")

        self.processing_history.append({
            "step": "1",
            "name": "æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–",
            "output": result
        })

        return result

    def step2_rag_comparison(self, claim1_requirements: List[str], 
                           prior_art_text: str) -> str:
        """
        ã‚¹ãƒ†ãƒƒãƒ—2: å¯¾æ¯”ç”¨RAGï¼ˆå…ˆè¡ŒæŠ€è¡“1ã‹ã‚‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆæŠ½å‡ºï¼‰
        
        Args:
            claim1_requirements: æœ¬é¡˜ã®ã‚¯ãƒ¬ãƒ¼ãƒ 1ã®è¦ä»¶ãƒªã‚¹ãƒˆ
            prior_art_text: å…ˆè¡ŒæŠ€è¡“1ã®å…¨æ–‡
            
        Returns:
            æŠ½å‡ºã•ã‚ŒãŸã‚¹ãƒ‹ãƒšãƒƒãƒˆãƒ†ã‚­ã‚¹ãƒˆ
        """
        print("\n" + "=" * 80)
        print("ğŸ” ã‚¹ãƒ†ãƒƒãƒ—2: å¯¾æ¯”ç”¨RAGï¼ˆã‚¹ãƒ‹ãƒšãƒƒãƒˆæŠ½å‡ºï¼‰")
        print("=" * 80)

        # å…ˆè¡ŒæŠ€è¡“1ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
        self.rag_system.index_document("PriorArt_1", prior_art_text)

        # å„è¦ä»¶ã‚’æ¤œç´¢ã‚¯ã‚¨ãƒªã¨ã—ã¦ä½¿ç”¨
        print(f"\næ¤œç´¢ã‚¯ã‚¨ãƒªæ•°: {len(claim1_requirements)}")
        snippets = self.rag_system.search(claim1_requirements, top_k=5)

        print(f"\nâœ… ã‚¹ãƒ‹ãƒšãƒƒãƒˆæŠ½å‡ºå®Œäº†ï¼ˆ{len(snippets.split('...'))}ä»¶ï¼‰")

        self.processing_history.append({
            "step": "2",
            "name": "å¯¾æ¯”ç”¨RAG",
            "queries": claim1_requirements,
            "output": snippets
        })

        return snippets

    def step3_claim_chart(self, claim1_requirements: List[str], 
                         prior_art_snippets: str) -> str:
        """
        ã‚¹ãƒ†ãƒƒãƒ—3: LLMã«ã‚ˆã‚‹å¯¾æ¯”è¡¨ï¼ˆã‚¯ãƒ¬ãƒ¼ãƒ ãƒãƒ£ãƒ¼ãƒˆï¼‰ã®ä½œæˆ
        
        Args:
            claim1_requirements: æœ¬é¡˜ã®ã‚¯ãƒ¬ãƒ¼ãƒ 1ã®è¦ä»¶ãƒªã‚¹ãƒˆ
            prior_art_snippets: å…ˆè¡ŒæŠ€è¡“1ã®é–¢é€£ã‚¹ãƒ‹ãƒšãƒƒãƒˆ
            
        Returns:
            å¯¾æ¯”è¡¨ï¼ˆMarkdownå½¢å¼ï¼‰
        """
        print("\n" + "=" * 80)
        print("ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—3: å¯¾æ¯”è¡¨ï¼ˆã‚¯ãƒ¬ãƒ¼ãƒ ãƒãƒ£ãƒ¼ãƒˆï¼‰ã®ä½œæˆ")
        print("=" * 80)

        prompt = PromptTemplates.STEP3_CLAIM_CHART.format(
            claim1_requirements=json.dumps(claim1_requirements, ensure_ascii=False, indent=2),
            prior_art_snippets=prior_art_snippets
        )

        claim_chart = self._generate_with_retry(use_json_model=False, prompt=prompt)

        print("\nâœ… å¯¾æ¯”è¡¨ä½œæˆå®Œäº†")
        print("\n" + "-" * 80)
        print(claim_chart[:500] + "..." if len(claim_chart) > 500 else claim_chart)
        print("-" * 80)

        self.processing_history.append({
            "step": "3",
            "name": "å¯¾æ¯”è¡¨ä½œæˆ",
            "output": claim_chart
        })

        return claim_chart

    def step4_novelty_judgement(self, claim_chart: str) -> Dict:
        """
        ã‚¹ãƒ†ãƒƒãƒ—4: LLMã«ã‚ˆã‚‹æ–°è¦æ€§ã®åˆ¤å®šã¨ã€Œç›¸é•ç‚¹ã€ã®ç¢ºå®š
        
        Args:
            claim_chart: ã‚¹ãƒ†ãƒƒãƒ—3ã§ä½œæˆã—ãŸå¯¾æ¯”è¡¨
            
        Returns:
            æ–°è¦æ€§åˆ¤å®šãƒ¬ãƒãƒ¼ãƒˆï¼ˆJSONï¼‰
        """
        print("\n" + "=" * 80)
        print("âš–ï¸ ã‚¹ãƒ†ãƒƒãƒ—4: æ–°è¦æ€§ã®åˆ¤å®šã¨ç›¸é•ç‚¹ã®ç¢ºå®š")
        print("=" * 80)

        prompt = PromptTemplates.STEP4_NOVELTY_JUDGEMENT.format(
            claim_chart=claim_chart
        )

        response_text = self._generate_with_retry(use_json_model=True, prompt=prompt)
        result = self._parse_json_response(response_text)

        print(f"\nâœ… æ–°è¦æ€§åˆ¤å®š: {result['novelty_judgement']}")
        if result['difference_points']:
            print(f"ç›¸é•ç‚¹æ•°: {len(result['difference_points'])}")
            for i, diff in enumerate(result['difference_points'], 1):
                print(f"  {i}. {diff[:100]}...")

        self.processing_history.append({
            "step": "4",
            "name": "æ–°è¦æ€§åˆ¤å®š",
            "output": result
        })

        return result

    def step5_motivation_search(self, problem: str, difference_points: List[str],
                               all_patents_text: str) -> str:
        """
        ã‚¹ãƒ†ãƒƒãƒ—5: é€²æ­©æ€§åˆ¤æ–­ã®ãŸã‚ã®ã€Œå‹•æ©Ÿä»˜ã‘ã€æ¤œç´¢ï¼ˆRAGï¼‰
        
        Args:
            problem: æœ¬é¡˜ã®èª²é¡Œ
            difference_points: ã‚¹ãƒ†ãƒƒãƒ—4ã§ç‰¹å®šã•ã‚ŒãŸç›¸é•ç‚¹
            all_patents_text: å…ˆè¡ŒæŠ€è¡“1ä»¥å¤–ã®å…¨ç‰¹è¨±æ–‡çŒ®
            
        Returns:
            å‹•æ©Ÿä»˜ã‘ã‚¹ãƒ‹ãƒšãƒƒãƒˆ
        """
        print("\n" + "=" * 80)
        print("ğŸ” ã‚¹ãƒ†ãƒƒãƒ—5: å‹•æ©Ÿä»˜ã‘æ¤œç´¢ï¼ˆRAGï¼‰")
        print("=" * 80)

        # å…¨ç‰¹è¨±DBã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
        self.rag_system.index_document("All_Patents", all_patents_text)

        # æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆï¼ˆèª²é¡Œ + ç›¸é•ç‚¹ï¼‰
        queries = [problem] + difference_points

        print(f"\næ¤œç´¢ã‚¯ã‚¨ãƒªæ•°: {len(queries)}")
        motivation_snippets = self.rag_system.search(queries, top_k=3)

        print(f"\nâœ… å‹•æ©Ÿä»˜ã‘ã‚¹ãƒ‹ãƒšãƒƒãƒˆæŠ½å‡ºå®Œäº†")

        self.processing_history.append({
            "step": "5",
            "name": "å‹•æ©Ÿä»˜ã‘æ¤œç´¢",
            "queries": queries,
            "output": motivation_snippets
        })

        return motivation_snippets

    def step6_inventive_step_judgement(self, application_data: Dict, 
                                      claim_chart: str,
                                      difference_points: List[str],
                                      motivation_snippets: str) -> Dict:
        """
        ã‚¹ãƒ†ãƒƒãƒ—6: LLMã«ã‚ˆã‚‹é€²æ­©æ€§ã®ã€Œä»®åˆ¤å®šã€ã¨ã€Œè‡ªä¿¡åº¦ã€è©•ä¾¡
        
        Args:
            application_data: æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿
            claim_chart: å¯¾æ¯”è¡¨
            difference_points: ç›¸é•ç‚¹ãƒªã‚¹ãƒˆ
            motivation_snippets: å‹•æ©Ÿä»˜ã‘ã‚¹ãƒ‹ãƒšãƒƒãƒˆ
            
        Returns:
            é€²æ­©æ€§åˆ¤å®šãƒ¬ãƒãƒ¼ãƒˆï¼ˆJSONï¼‰
        """
        print("\n" + "=" * 80)
        print("âš–ï¸ ã‚¹ãƒ†ãƒƒãƒ—6: é€²æ­©æ€§ã®ä»®åˆ¤å®šã¨è‡ªä¿¡åº¦è©•ä¾¡")
        print("=" * 80)

        prompt = PromptTemplates.STEP6_INVENTIVE_STEP.format(
            application_data=json.dumps(application_data, ensure_ascii=False, indent=2),
            claim_chart=claim_chart,
            difference_points=json.dumps(difference_points, ensure_ascii=False, indent=2),
            motivation_snippets=motivation_snippets
        )

        response_text = self._generate_with_retry(use_json_model=True, prompt=prompt)
        result = self._parse_json_response(response_text)

        print(f"\nâœ… é€²æ­©æ€§ä»®åˆ¤å®š: {result['judgement']}")
        print(f"è‡ªä¿¡åº¦: {result['confidence']}")
        if result.get('low_confidence_points'):
            print(f"\nâš ï¸ ä½è‡ªä¿¡åº¦ãƒã‚¤ãƒ³ãƒˆæ•°: {len(result['low_confidence_points'])}")
            for i, point in enumerate(result['low_confidence_points'], 1):
                print(f"  {i}. {point[:100]}...")

        self.processing_history.append({
            "step": "6",
            "name": "é€²æ­©æ€§ä»®åˆ¤å®š",
            "output": result
        })

        return result

    def step7_prepare_human_review(self) -> Dict:
        """
        ã‚¹ãƒ†ãƒƒãƒ—7: äººé–“ï¼ˆå°‚é–€å®¶ï¼‰ã«ã‚ˆã‚‹æœ€çµ‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        
        Returns:
            äººé–“ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ãƒ‡ãƒ¼ã‚¿
        """
        print("\n" + "=" * 80)
        print("ğŸ‘¤ ã‚¹ãƒ†ãƒƒãƒ—7: äººé–“ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™")
        print("=" * 80)

        review_data = {
            "processing_history": self.processing_history,
            "review_instructions": """
ã€äººé–“ãƒ¬ãƒ“ãƒ¥ãƒ¼æŒ‡ç¤ºã€‘
1. ã‚¹ãƒ†ãƒƒãƒ—6ã®ã€Œjudgementã€ã¨ã€Œconfidenceã€ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
2. ã€Œconfidenceã€ãŒã€Œä¸­ã€ã¾ãŸã¯ã€Œä½ã€ã®å ´åˆã€ã€Œlow_confidence_pointsã€ã‚’é›†ä¸­çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ã€‚
3. å¿…è¦ã«å¿œã˜ã¦è¿½åŠ èª¿æŸ»ã‚’å®Ÿæ–½ã—ã€æœ€çµ‚åˆ¤æ–­ã‚’ä¸‹ã—ã¦ãã ã•ã„ã€‚
4. æœ€çµ‚åˆ¤æ–­ã‚’ä»¥ä¸‹ã®å½¢å¼ã§è¨˜éŒ²ã—ã¦ãã ã•ã„ï¼š
   - é€²æ­©æ€§ã®æœ‰ç„¡: [ã‚ã‚Š/ãªã—]
   - åˆ¤æ–­ç†ç”±: [è©³ç´°ãªç†ç”±]
   - è¿½åŠ èª¿æŸ»å†…å®¹: [å®Ÿæ–½ã—ãŸè¿½åŠ èª¿æŸ»ã®å†…å®¹]
"""
        }

        print("\nâœ… äººé–“ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†")

        return review_data

    def run_full_examination(self, application_text: str, 
                           prior_art_1_text: str,
                           all_patents_text: str) -> Dict:
        """
        å®Œå…¨ãªå¯©æŸ»ãƒ—ãƒ­ã‚»ã‚¹ã®å®Ÿè¡Œ
        
        Args:
            application_text: æœ¬é¡˜ç™ºæ˜ã®ãƒ†ã‚­ã‚¹ãƒˆ
            prior_art_1_text: å…ˆè¡ŒæŠ€è¡“1ã®ãƒ†ã‚­ã‚¹ãƒˆ
            all_patents_text: å…ˆè¡ŒæŠ€è¡“1ä»¥å¤–ã®å…¨ç‰¹è¨±æ–‡çŒ®
            
        Returns:
            å¯©æŸ»çµæœã®è¾æ›¸
        """
        print("\n" + "ğŸš€" * 40)
        print("ç‰¹è¨±å¯©æŸ»ãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹ (RAGçµ±åˆç‰ˆ)")
        print("ğŸš€" * 40)

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: æœ¬é¡˜ç™ºæ˜ã®æ§‹é€ åŒ–
            app_data = self.step1_structure_application(application_text)

            # ã‚¹ãƒ†ãƒƒãƒ—2: å¯¾æ¯”ç”¨RAG
            prior_art_snippets = self.step2_rag_comparison(
                app_data['claim1_requirements'],
                prior_art_1_text
            )

            # ã‚¹ãƒ†ãƒƒãƒ—3: å¯¾æ¯”è¡¨ä½œæˆ
            claim_chart = self.step3_claim_chart(
                app_data['claim1_requirements'],
                prior_art_snippets
            )

            # ã‚¹ãƒ†ãƒƒãƒ—4: æ–°è¦æ€§åˆ¤å®š
            novelty_report = self.step4_novelty_judgement(claim_chart)

            # æ–°è¦æ€§ãŒãªã„å ´åˆã¯ã€é€²æ­©æ€§åˆ¤å®šã‚’ã‚¹ã‚­ãƒƒãƒ—
            if novelty_report['novelty_judgement'] == 'ãªã—':
                print("\nâš ï¸ æ–°è¦æ€§ãªã—ã€‚é€²æ­©æ€§åˆ¤å®šã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                inventive_step_report = {
                    "judgement": "é€²æ­©æ€§ãªã—",
                    "confidence": "é«˜",
                    "rationale": "æ–°è¦æ€§ãŒãªã„ãŸã‚ã€é€²æ­©æ€§ã‚‚èªã‚ã‚‰ã‚Œã¾ã›ã‚“ã€‚",
                    "low_confidence_points": []
                }
            else:
                # ã‚¹ãƒ†ãƒƒãƒ—5: å‹•æ©Ÿä»˜ã‘æ¤œç´¢
                motivation_snippets = self.step5_motivation_search(
                    app_data['problem'],
                    novelty_report['difference_points'],
                    all_patents_text
                )

                # ã‚¹ãƒ†ãƒƒãƒ—6: é€²æ­©æ€§ä»®åˆ¤å®š
                inventive_step_report = self.step6_inventive_step_judgement(
                    app_data,
                    claim_chart,
                    novelty_report['difference_points'],
                    motivation_snippets
                )

            # ã‚¹ãƒ†ãƒƒãƒ—7: äººé–“ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
            human_review_data = self.step7_prepare_human_review()

            print("\n" + "âœ…" * 40)
            print("ç‰¹è¨±å¯©æŸ»ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†")
            print("âœ…" * 40)

            return {
                "step1_application_structure": app_data,
                "step2_prior_art_snippets": prior_art_snippets,
                "step3_claim_chart": claim_chart,
                "step4_novelty_report": novelty_report,
                "step6_inventive_step_report": inventive_step_report,
                "step7_human_review_data": human_review_data,
                "summary": {
                    "novelty": novelty_report['novelty_judgement'],
                    "inventive_step": inventive_step_report['judgement'],
                    "confidence": inventive_step_report['confidence'],
                    "requires_human_review": inventive_step_report['confidence'] in ['ä¸­', 'ä½']
                }
            }

        except Exception as e:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()
            return {
                "error": str(e),
                "processing_history": self.processing_history,
                "partial_results": "å‡¦ç†ãŒé€”ä¸­ã§ä¸­æ–­ã•ã‚Œã¾ã—ãŸ"
            }

    def save_results(self, results: Dict, output_path: str):
        """
        å¯©æŸ»çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        
        Args:
            results: å¯©æŸ»çµæœã®è¾æ›¸
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")


# ==================== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•° ====================

def entry(application_dict: Dict, prior_art_dict: Dict, 
         all_patents_dict: Optional[Dict] = None):
    """
    ç‰¹è¨±å¯©æŸ»ã‚’å®Ÿè¡Œã—ã€çµæœã‚’è¿”ã™
    
    Args:
        application_dict: æœ¬é¡˜ç™ºæ˜ã®ãƒ†ã‚­ã‚¹ãƒˆè¾æ›¸
            ä¾‹: {"abstract": "...", "claims": "..."}
        prior_art_dict: å…ˆè¡ŒæŠ€è¡“1ã®ãƒ†ã‚­ã‚¹ãƒˆè¾æ›¸
            ä¾‹: {"abstract": "...", "claims": "..."}
        all_patents_dict: ãã®ä»–ã®å…¨ç‰¹è¨±æ–‡çŒ®ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            ä¾‹: {"document1": "...", "document2": "..."}
    
    Returns:
        dict: å¯©æŸ»çµæœã®è¾æ›¸ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
    """
    try:
        # config.envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
        load_dotenv('config.env')

        # APIã‚­ãƒ¼ã®è¨­å®š
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            print("âš ï¸ config.envãƒ•ã‚¡ã‚¤ãƒ«ã«GOOGLE_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„")
            return None

        # ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        system = PatentExaminationSystemRAG(api_key)

        # ãƒ†ã‚­ã‚¹ãƒˆã®çµ±åˆ
        application_text = f"""Abstract: {application_dict.get('abstract', '')}

Claims: {application_dict.get('claims', '')}"""

        prior_art_1_text = f"""Abstract: {prior_art_dict.get('abstract', '')}

Claims: {prior_art_dict.get('claims', '')}"""

        # å…¨ç‰¹è¨±æ–‡çŒ®ã®çµ±åˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        all_patents_text = ""
        if all_patents_dict:
            all_patents_text = "\n\n".join(all_patents_dict.values())
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§å…ˆè¡ŒæŠ€è¡“1ä»¥å¤–ã®æ¶ç©ºã®æ–‡çŒ®ã‚’è¿½åŠ 
            all_patents_text = """
[æ–‡çŒ®A] ãƒ—ãƒ©ã‚ºãƒCVDæ³•ã‚’æ”¹è‰¯ã—ã€DLCè†œã®ç¡¬åº¦ã‚’æœ€å¤§6Gpaã¾ã§é«˜ã‚ã‚‹ã“ã¨ã«æˆåŠŸã—ãŸã€‚
[æ–‡çŒ®B] é«˜æ¸©ç’°å¢ƒä¸‹ã§ã®ä½¿ç”¨ï¼ˆ350â„ƒï¼‰ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€DLCè†œã«ã‚·ãƒªã‚³ãƒ³ï¼ˆSiï¼‰ã‚’ãƒ‰ãƒ¼ãƒ—ã™ã‚‹ã“ã¨ã§è€ç†±æ€§ã‚’350â„ƒã¾ã§å‘ä¸Šã•ã›ãŸã€‚
"""

        # å®Œå…¨ãªå¯©æŸ»ãƒ—ãƒ­ã‚»ã‚¹ã®å®Ÿè¡Œ
        results = system.run_full_examination(
            application_text,
            prior_art_1_text,
            all_patents_text
        )

        return results

    except ValueError as e:
        print(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    sample_application = {
        "abstract": "ã‚¤ãƒ³ã‚¯ã‚¸ã‚§ãƒƒãƒˆãƒã‚ºãƒ«ã®è€æ‘©è€—æ€§ã¨è€ç†±æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚",
        "claims": """ã€è«‹æ±‚é …ï¼‘ã€‘
ç‚­åŒ–ã‚±ã‚¤ç´ ï¼ˆSiCï¼‰ã‹ã‚‰ãªã‚‹åŸºæã¨ã€
å‰è¨˜åŸºæä¸Šã«å½¢æˆã•ã‚ŒãŸã€ãƒ€ã‚¤ãƒ¤ãƒ¢ãƒ³ãƒ‰ãƒ©ã‚¤ã‚¯ã‚«ãƒ¼ãƒœãƒ³ï¼ˆDLCï¼‰è†œã¨ã€
å‰è¨˜DLCè†œãŒã€5Gpaä»¥ä¸Šã®ç¡¬åº¦ã¨ã€300â„ƒä»¥ä¸Šã®è€ç†±æ€§ã‚’æœ‰ã™ã‚‹ã“ã¨ã‚’ç‰¹å¾´ã¨ã™ã‚‹ã€ãƒã‚ºãƒ«ãƒ˜ãƒƒãƒ‰ã€‚"""
    }

    sample_prior_art = {
        "abstract": "é«˜æ¸©åŠ ç†±ã«ã‚ˆã‚‹è¡¨é¢ç‰¹æ€§ã®ä½ä¸‹ã‚’é˜²æ­¢ã—ã€æ±šã‚Œã‚’ä½æ¸›ã™ã‚‹ã€‚",
        "claims": """ã€è«‹æ±‚é …ï¼‘ã€‘
[0025] æœ¬ç™ºæ˜ã®ãƒã‚ºãƒ«ã¯ã€åŸºæã¨ã—ã¦ç‚­åŒ–ã‚±ã‚¤ç´ ï¼ˆSiCï¼‰ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€å„ªã‚ŒãŸå‰›æ€§ã‚’ç¢ºä¿ã™ã‚‹ã€‚
[0038] è€æ‘©è€—æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã€è¡¨é¢ã«DLCï¼ˆãƒ€ã‚¤ãƒ¤ãƒ¢ãƒ³ãƒ‰ãƒ©ã‚¤ã‚¯ã‚«ãƒ¼ãƒœãƒ³ï¼‰ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’æ–½ã™ã€‚
[0042] å®Ÿæ–½ä¾‹ï¼‘ã®DLCè†œã¯ã€ãƒŠãƒã‚¤ãƒ³ãƒ‡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è©¦é¨“ã«ãŠã„ã¦4.5Gpaã®ç¡¬åº¦ã‚’ç¤ºã—ãŸã€‚
[0056] ç†±å®‰å®šæ€§è©¦é¨“ã«ãŠã„ã¦ã€æœ¬ã‚³ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¯250â„ƒã¾ã§ã®ç’°å¢ƒä¸‹ã§å®‰å®šã—ãŸç‰¹æ€§ã‚’ç¶­æŒã—ãŸã€‚"""
    }

    print("=" * 80)
    print("ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–‹å§‹")
    print("=" * 80)

    results = entry(sample_application, sample_prior_art)

    if results and "error" not in results:
        print("\n" + "=" * 80)
        print("ğŸ“Š æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼")
        print("=" * 80)
        print(f"æ–°è¦æ€§: {results['summary']['novelty']}")
        print(f"é€²æ­©æ€§: {results['summary']['inventive_step']}")
        print(f"è‡ªä¿¡åº¦: {results['summary']['confidence']}")
        print(f"äººé–“ãƒ¬ãƒ“ãƒ¥ãƒ¼å¿…è¦: {results['summary']['requires_human_review']}")